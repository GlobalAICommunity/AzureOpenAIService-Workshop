"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[944],{1376:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var i=n(7624),r=n(4552);const s={},a="Image Generation",o={id:"Part-3-labs/Image Generation",title:"Image Generation",description:"Welcome to part 2 of this workshop, where we will interact with a text-to-image model, DALL-E 3. Start by clicking on the Images playground, and selecting dall-e-3 from the deployments drop-down menu.",source:"@site/docs/06-Part-3-labs/01-Image Generation.md",sourceDirName:"06-Part-3-labs",slug:"/Part-3-labs/Image Generation",permalink:"/Part-3-labs/Image Generation",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Function Calling",permalink:"/Part-2-labs/Function-Calling"},next:{title:"AI Models & Deployments",permalink:"/ai-models"}},l={},c=[{value:"Creating our first images",id:"creating-our-first-images",level:2},{value:"Be specific",id:"be-specific",level:3},{value:"Best practices",id:"best-practices",level:3}];function d(e){const t={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,r.M)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"image-generation",children:"Image Generation"}),"\n",(0,i.jsxs)(t.p,{children:["Welcome to part 2 of this workshop, where we will interact with a text-to-image model, DALL-E 3. Start by clicking on the ",(0,i.jsx)(t.strong,{children:"Images"})," playground, and selecting ",(0,i.jsx)(t.strong,{children:"dall-e-3"})," from the deployments drop-down menu."]}),"\n",(0,i.jsx)(t.h2,{id:"creating-our-first-images",children:"Creating our first images"}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsxs)(t.p,{children:["[!TIP]\nWhat is DALL-E 3? DALL-E 3 is a neural network based model that can generate graphical data from ",(0,i.jsx)(t.strong,{children:"natural language input"}),". Put more simply, you can provide DALL-E 3 with a ",(0,i.jsx)(t.strong,{children:"description"})," and it can generate an appropriate image."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Let's begin with generating an image by entering a basic prompt in the description box, then clicking on generate:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",metastring:'title="Enter in the user prompt:"',children:"A corgi practicing karate\n"})}),"\n",(0,i.jsx)(t.p,{children:"Images generated by DALL-E 3 are original; they are not retrieved from a curated image catalog. In other words, DALL-E 3 is not a search system for finding appropriate images - it is an artificial intelligence (AI) model that generates new images based on the data on which it was trained."}),"\n",(0,i.jsx)(t.h3,{id:"be-specific",children:"Be specific"}),"\n",(0,i.jsx)(t.p,{children:"Details allow for more accurate responses. Similar to text generation, image generation models greatly benefit from detailed descriptions of what you are looking to generate."}),"\n",(0,i.jsx)(t.p,{children:"For example, enter the following prompt:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",metastring:'title="Enter in the user prompt:"',children:"An elephant on a skateboard\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Then select ",(0,i.jsx)(t.strong,{children:"Generate"})," and view the image that is generated."]}),"\n",(0,i.jsx)(t.p,{children:"Now, let's modify the prompt by adding more details to the description:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",metastring:'title="Enter in the user prompt:"',children:"A purple elephant on a skateboard performing an ollie, in the style of Picasso\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Select ",(0,i.jsx)(t.strong,{children:"Generate"})," once again and compare the results."]}),"\n",(0,i.jsx)(t.h3,{id:"best-practices",children:"Best practices"}),"\n",(0,i.jsx)(t.p,{children:"To create effective and accurate images with DALL-E 3, here are some best practices to follow:"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Clear and descriptive prompts"}),": Craft your text prompts to be clear and detailed. The more specific you are with your description, the more likely DALL-E 3 will generate an image that matches your request. Include attributes such as the subject, action, environment, style, and any important details."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Use of adjectives"}),": Employ adjectives and adverbs to describe the qualities, emotions, and characteristics you want the image to convey. This helps in refining the generated image to better match your vision."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Balance detail with simplicity"}),": While details are important, overly complicated or contradictory prompts can confuse the AI, leading to unexpected results. Aim for a balance where your description provides enough context without being overly convoluted."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Experiment with different styles"}),": Specify artistic styles or influences if you want your image to have a particular aesthetic. For example, you could ask for an image in the style of Van Gogh or futuristic concept art."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Iterative approach"}),": Often, the first image generated may not be perfect. Use it as a starting point and iteratively refine your prompt based on the output to get closer to your desired result."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Aspect ratio and composition"}),": If you have a preference for the image\u2019s composition or aspect ratio, include it in your prompt. For example, you might request a landscape-oriented image or a portrait with a subject off-center."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Cultural and contextual references"}),": If appropriate, include cultural or historical references to provide additional context that can help guide the image generation process."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Ethical considerations"}),": Be mindful of the ethical implications of your prompts. Avoid creating images that are offensive, perpetuate stereotypes, or infringe on copyrights."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Testing and learning"}),": Experiment with different prompts to understand how DALL-E 3 interprets various descriptions. This learning process can help you improve the precision of your prompts over time."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Following guidelines"}),": Adhere to OpenAI's use-case policy and content guidelines when creating prompts. Avoid requesting images that are not allowed as per OpenAI's content policy."]}),"\n"]}),"\n"]})]})}function p(e={}){const{wrapper:t}={...(0,r.M)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},4552:(e,t,n)=>{n.d(t,{I:()=>o,M:()=>a});var i=n(1504);const r={},s=i.createContext(r);function a(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);