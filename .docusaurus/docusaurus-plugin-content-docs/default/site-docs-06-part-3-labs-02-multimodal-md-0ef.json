{
  "id": "Part-3-labs/Multimodal",
  "title": "Multimodal",
  "description": "By now we have interacted with LLMs using a single modality: inputting text and receiving either text or images. However, multimodal interfaces are becoming increasingly popular, as they allow users to interact with models using multiple modalities, such as text, images, and speech, thus facilitating human-computer interactions. In this section, we will explore how to use multimodal interfaces to interact with GPT-4o.",
  "source": "@site/docs/06-Part-3-labs/02-Multimodal.md",
  "sourceDirName": "06-Part-3-labs",
  "slug": "/Part-3-labs/Multimodal",
  "permalink": "/Part-3-labs/Multimodal",
  "draft": false,
  "unlisted": false,
  "tags": [],
  "version": "current",
  "sidebarPosition": 2,
  "frontMatter": {},
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Function Calling",
    "permalink": "/Part-2-labs/Function-Calling"
  },
  "next": {
    "title": "AI Models & Deployments",
    "permalink": "/ai-models"
  }
}